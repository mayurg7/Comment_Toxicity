# -*- coding: utf-8 -*-
"""Comment_Toxicity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xQJnf2tvM3_kcC1mcX_GDT4jXokLZ1ZE
"""

pip install tensorflow tensorflow gpu pandas matplotlib sklearn

import os
import pandas as pd
import tensorflow as tf
import numpy as np

df = pd.read_csv(os.path.join("train.csv"))

df.head()

df.iloc[0]['comment_text']

df[df.columns[2:]].iloc[3]

from tensorflow.keras.layers import TextVectorization

x = df['comment_text']
y = df[df.columns[2:]].values

df.columns

df[df.columns[2:]].values

MAX_FEATURES = 200000

vectorizer = TextVectorization(max_tokens = MAX_FEATURES,
                               output_sequence_length = 1800,
                               output_mode = 'int')

vectorizer.adapt(x.values)

vectorizer.get_vocabulary()

vectorizer_text = vectorizer(x.values)

vectorizer_text

dataset = tf.data.Dataset.from_tensor_slices((vectorizer_text,y))
dataset = dataset.cache()
dataset = dataset.shuffle(160000)
dataset = dataset.batch(16)
dataset = dataset.prefetch(8)

batch_x, batch_y=dataset.as_numpy_iterator().next()

train = dataset.take(int(len(dataset)*.7))
val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))
test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))

train_gen = train.as_numpy_iterator()

train_gen.next()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding

model = Sequential()
model.add(Embedding(MAX_FEATURES+1,32))
model.add(Bidirectional(LSTM(32, activation='tanh')))
model.add(Dense(128,activation='relu'))
model.add(Dense(256,activation='relu'))
model.add(Dense(128,activation='relu'))
model.add(Dense(6,activation='sigmoid'))

model.compile(loss='BinaryCrossentropy',optimizer='Adam')

model.summary()

history = model.fit(train,epochs=10, validation_data=val)

history.history

from matplotlib import pyplot as plt

plt.figure(figsize=(8,5))
pd.DataFrame(history.history).plot()
plt.show()



input_text = vectorizer('You freaking suck!')

df.columns[2:]

batch = test.as_numpy_iterator().next()

batch_x, batch_y = test.as_numpy_iterator().next()

(model.predict(batch_x)>0.5).astype(int)

model.predict(np.expand_dims(input_text,0))

res = model.predict(np.expand_dims(input_text,0))

from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy

pre = Precision()
re = Recall()
acc = CategoricalAccuracy()

for batch in test.as_numpy_iterator():
  x_true, y_true = batch
  yhat = model.predict(x_true)

  y_true = y_true.flatten()
  yhat = yhat.flatten()

  pre.update_state(y_true, yhat)
  re.update_state(y_true, yhat)
  acc.update_state(y_true, yhat)

print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')

!pip install gradio jinja2

!pip install kaleido

import gradio as gr

model.save('Comment_toxicity.h5')

model = tf.keras.models.load_model('Comment_toxicity.h5')

input_str = vectorizer(' hey i freaking hate you!')

res  = model.predict(np.expand_dims(input_str,0))

res

def score_comment(comment):
  vectorized_comment = vectorizer([comment])
  results = model.predict(vectorized_comment)

  text = ''
  for idx, col in enumeric(df.columns[2:1]):
    text += '{}: {}\n'.format(col, results[0][idx]>0.5)

  return text

interface = gr.Interface(fn = score_comment,
                         inputs = gr.inputs.Textbox(lines=2, placeholder = 'Comment to score'),
                         outputs='text')

interface.launch(share=True)